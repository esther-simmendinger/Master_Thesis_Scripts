{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Thesis Script\n",
    "## Sentiment classification of tweets using RoBERTa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step: Use Twitter Sentiment BERT to classify each Tweet into neutral, positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installations\n",
    "#!pip install transformers\n",
    "#!pip install tensorflow\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T08:51:15.076910Z",
     "iopub.status.busy": "2023-05-02T08:51:15.076524Z",
     "iopub.status.idle": "2023-05-02T08:51:15.082830Z",
     "shell.execute_reply": "2023-05-02T08:51:15.081830Z",
     "shell.execute_reply.started": "2023-05-02T08:51:15.076877Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import regex as re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T08:51:24.692856Z",
     "iopub.status.busy": "2023-05-02T08:51:24.692394Z",
     "iopub.status.idle": "2023-05-02T08:52:22.917008Z",
     "shell.execute_reply": "2023-05-02T08:52:22.916003Z",
     "shell.execute_reply.started": "2023-05-02T08:51:24.692815Z"
    }
   },
   "outputs": [],
   "source": [
    "f = open(r'/kaggle/input/twitter-data2/Merged_Data_20230501_2.json')\n",
    "  \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = pd.read_json(f)\n",
    "  \n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T08:52:25.081832Z",
     "iopub.status.busy": "2023-05-02T08:52:25.081490Z",
     "iopub.status.idle": "2023-05-02T08:52:25.088889Z",
     "shell.execute_reply": "2023-05-02T08:52:25.087930Z",
     "shell.execute_reply.started": "2023-05-02T08:52:25.081803Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T08:52:27.451730Z",
     "iopub.status.busy": "2023-05-02T08:52:27.451294Z",
     "iopub.status.idle": "2023-05-02T08:52:28.244543Z",
     "shell.execute_reply": "2023-05-02T08:52:28.243571Z",
     "shell.execute_reply.started": "2023-05-02T08:52:27.451698Z"
    }
   },
   "outputs": [],
   "source": [
    "# only need to look at orginal tweets for this\n",
    "data_OG = data[(data['referenced_tweets.retweeted.id'] == \"None\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T08:52:28.246801Z",
     "iopub.status.busy": "2023-05-02T08:52:28.246286Z",
     "iopub.status.idle": "2023-05-02T08:52:28.254386Z",
     "shell.execute_reply": "2023-05-02T08:52:28.253467Z",
     "shell.execute_reply.started": "2023-05-02T08:52:28.246769Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(data_OG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we only look at original tweets, we have 542,104 observations. We only classify tweet text for these.\n",
    "Continue with Twitter BERT.\n",
    "The following model is used: https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T08:52:58.959477Z",
     "iopub.status.busy": "2023-05-02T08:52:58.959040Z",
     "iopub.status.idle": "2023-05-02T08:52:58.970163Z",
     "shell.execute_reply": "2023-05-02T08:52:58.968742Z",
     "shell.execute_reply.started": "2023-05-02T08:52:58.959441Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T08:52:33.298591Z",
     "iopub.status.busy": "2023-05-02T08:52:33.298251Z",
     "iopub.status.idle": "2023-05-02T08:52:33.306392Z",
     "shell.execute_reply": "2023-05-02T08:52:33.305530Z",
     "shell.execute_reply.started": "2023-05-02T08:52:33.298562Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T08:53:01.756840Z",
     "iopub.status.busy": "2023-05-02T08:53:01.756382Z",
     "iopub.status.idle": "2023-05-02T08:53:05.022173Z",
     "shell.execute_reply": "2023-05-02T08:53:05.020974Z",
     "shell.execute_reply.started": "2023-05-02T08:53:01.756799Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T08:53:09.392020Z",
     "iopub.status.busy": "2023-05-02T08:53:09.391622Z",
     "iopub.status.idle": "2023-05-02T08:53:09.529742Z",
     "shell.execute_reply": "2023-05-02T08:53:09.528571Z",
     "shell.execute_reply.started": "2023-05-02T08:53:09.391987Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cconnect to GPU and push model to GPU\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-05-02T08:53:11.092741Z",
     "iopub.status.busy": "2023-05-02T08:53:11.091580Z",
     "iopub.status.idle": "2023-05-02T08:53:16.351882Z",
     "shell.execute_reply": "2023-05-02T08:53:16.350824Z",
     "shell.execute_reply.started": "2023-05-02T08:53:11.092695Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T08:53:32.446595Z",
     "iopub.status.busy": "2023-05-02T08:53:32.446185Z",
     "iopub.status.idle": "2023-05-02T08:53:32.476831Z",
     "shell.execute_reply": "2023-05-02T08:53:32.475576Z",
     "shell.execute_reply.started": "2023-05-02T08:53:32.446563Z"
    }
   },
   "outputs": [],
   "source": [
    "tweet_text = data_OG.text.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T08:53:34.215929Z",
     "iopub.status.busy": "2023-05-02T08:53:34.215493Z",
     "iopub.status.idle": "2023-05-02T08:53:34.223272Z",
     "shell.execute_reply": "2023-05-02T08:53:34.222231Z",
     "shell.execute_reply.started": "2023-05-02T08:53:34.215853Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove emojis\n",
    "def deEmojify(inputString):\n",
    "    return inputString.encode('ascii', 'ignore').decode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T08:53:35.467982Z",
     "iopub.status.busy": "2023-05-02T08:53:35.467579Z",
     "iopub.status.idle": "2023-05-02T08:53:41.023477Z",
     "shell.execute_reply": "2023-05-02T08:53:41.022367Z",
     "shell.execute_reply.started": "2023-05-02T08:53:35.467950Z"
    }
   },
   "outputs": [],
   "source": [
    "tweet_text_lst_clean = []\n",
    "for item in tweet_text:\n",
    "    item_new = re.sub(\"&amp;\", \"&\", item)\n",
    "    #item_new = re.sub(\"https.*\", \"\", item_new)\n",
    "    #item_new = re.sub(\"@\\w+\", \"\", item_new)\n",
    "    item_new = deEmojify(item_new)\n",
    "    item_new = item_new.replace('\\\\n', ' ')\n",
    "    item_new = item_new.replace('\\\\', '')\n",
    "    tweet_text_lst_clean.append(item_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T08:53:48.135936Z",
     "iopub.status.busy": "2023-05-02T08:53:48.135509Z",
     "iopub.status.idle": "2023-05-02T08:53:48.144143Z",
     "shell.execute_reply": "2023-05-02T08:53:48.143106Z",
     "shell.execute_reply.started": "2023-05-02T08:53:48.135896Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_lst(text_lst):\n",
    "    sentiment_results = []\n",
    "    for text in text_lst:\n",
    "        text = preprocess(text)\n",
    "        encoded_input = tokenizer(text, return_tensors='pt')\n",
    "        encoded_input.to(device)\n",
    "        output = model(**encoded_input)\n",
    "        output = output.logits\n",
    "        output = output.cpu()\n",
    "        scores = output[0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "\n",
    "        ranking = np.argsort(scores)\n",
    "        ranking = ranking[::-1]\n",
    "        result_dict = {}\n",
    "        for i in range(scores.shape[0]):\n",
    "            l = config.id2label[ranking[i]]\n",
    "            s = scores[ranking[i]]\n",
    "            result_dict[l] = s\n",
    "            #print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
    "        sentiment_results.append(result_dict)\n",
    "        \n",
    "    return sentiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T08:53:55.854759Z",
     "iopub.status.busy": "2023-05-02T08:53:55.854388Z",
     "iopub.status.idle": "2023-05-02T08:53:58.099161Z",
     "shell.execute_reply": "2023-05-02T08:53:58.098090Z",
     "shell.execute_reply.started": "2023-05-02T08:53:55.854727Z"
    }
   },
   "outputs": [],
   "source": [
    "tweet_sentiment_results = preprocess_lst(tweet_text_lst_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T08:54:00.491456Z",
     "iopub.status.busy": "2023-05-02T08:54:00.488445Z",
     "iopub.status.idle": "2023-05-02T08:54:00.498667Z",
     "shell.execute_reply": "2023-05-02T08:54:00.497530Z",
     "shell.execute_reply.started": "2023-05-02T08:54:00.491417Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_bert_df = pd.DataFrame(tweet_sentiment_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T08:40:18.500680Z",
     "iopub.status.busy": "2023-05-02T08:40:18.500334Z",
     "iopub.status.idle": "2023-05-02T08:40:18.513374Z",
     "shell.execute_reply": "2023-05-02T08:40:18.512321Z",
     "shell.execute_reply.started": "2023-05-02T08:40:18.500652Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_bert_df.to_csv(\"Sentiment_BERT_results_complete.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we add the ordered dict of all three sentiments with their scores to the dataset.\n",
    "This is because after taking a quick look at the results, the highest scored sentiment is not always the most fitting.\n",
    "So there might be the need to use some kind of combination of the 2 highest scores, for instance. Therefore, we do not discard any lower-scored sentiments as of now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
